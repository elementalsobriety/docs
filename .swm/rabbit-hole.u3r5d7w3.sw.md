---
title: Rabbit Hole
---
Howdy howdy.

Have you even fallen down a rabbit hole? Lost an entire evening to TikTok or gone to sleep whilst watching shark attacks on YouTube?

Yup. I hear you. After I wrote my post on The Algorithm's Invisible Hand, the same thing happened to me. In part out of idle interest and in part down to Kyle Chayka's book, Filterworld.

Which, in turn, I discovered as a result of my idle interest!

Or did I? Maybe "the algorithm" was stalking me?

Time for a quick refresher, methinks.

In recent times, algorithmic recommendation systems have become ubiquitous in our digital lives, shaping the content we consume, the products we buy, and the experiences we have online. From the music we stream to the movies and TV shows we watch, from the news articles that appear in our social media feeds to the ads that follow us around the web, algorithms are constantly working behind the scenes to curate our digital world.

On the surface, these recommendation systems offer convenience and personalisation, promising to connect us with content that aligns with our interests and preferences.

However, in his awesome book Filterworld, Chayka argues in that this algorithmic curation comes with some pretty thought provoking hidden costs. In principle, Kyle-E-Boy suggests that the pervasive influence of recommendation algorithms is making us docile consumers, flattening our tastes, and eroding our sense of agency and discovery.

On the face of it I think he's probably bang on there, but wanted to muse my way through the idea. And I thought I'd bring you along. Hope you don't mind.

I also want to see if / how these algorithmic recommendations might embody some of the key characteristics of postmodernism, such as the fragmentation of culture, the blurring of boundaries and the loss of authenticity.

Like you do.

So, today's tram-ponder is all about how I think these systems interact with existing social hierarchies and power dynamics, and how they might be reshaping the struggle for cultural distinction in today's "digital" age.

After all, as we know, trams are great places for a mental meander, right?

The Fragmentation of Culture.

One of the defining features of postmodernism is the fragmentation of culture, the breakdown of grand narratives and overarching structures of meaning. In the postmodern world, culture becomes a kaleidoscope of micro-narratives and niche identities, each with its own set of values, aesthetics, and ways of knowing.

Algorithmic recommendation systems inevitably both reflect and accelerate this sense of cultural fragmentation. By looking at our digital footprints - the songs we listen to, the movies we watch, the links we click - these systems construct personalised micro-worlds for each individual. Two people using the same streaming service or social media platform are bound to have radically different experiences based on their algorithmically-determined profiles.

So far so good? On one level, this fragmentation can be seen as a form of cultural democratisation, allowing niche communities and marginalised voices to find their audiences. (Think: partisan thinkers and outliners...) However, for me at least, it also raises concerns about the erosion of shared cultural experiences and the potential for "echo chambers" and "filter bubbles". When our digital lives are increasingly tailored to our existing preferences, we are less likely to encounter ideas and perspectives that challenge our beliefs or expand our horizons.

The algorithmic fragmentation of culture is making it more difficult to grasp the bigger picture, to understand how our individual experiences fit into larger social and political contexts.

In a world of micro-targeted content, it becomes easier to lose sight of the macro-level forces that shape our lives.

The Blurring of Boundaries.

Another hallmark of postmodernism is the blurring of boundaries between previously distinct cultural categories and hierarchies.

Let me try and explain what I mean:

High culture and low culture, art and commerce, original and copy - these binary oppositions break down in the postmodern world, giving way to a more fluid and hybrid cultural landscape.

These pesky algorithmic recommendation systems contribute to this boundary-blurring in several distinct ways. Firstly, by prioritising popularity and similarity over traditional markers of cultural value, they are eroding the distinction between "high" and "low" culture. While browsing Netflix, for example, you might be recommended a critically-acclaimed art film alongside a lowbrow comedy, not because of any inherent quality difference, but because other users with similar viewing histories have watched both.

Moving on, algorithmic systems definitely blur the line between content and advertising, or between organic expression and commercial influence. Sponsored posts and promoted products are woven seamlessly into our social media feeds and search results, often with only minimal disclosure. The rise of influencer marketing further complicates this picture, as algorithmic systems elevate the voices of individuals who can effectively blend personal authenticity with brand promotion.

Don't you just love 'em?

Finally, the very nature of algorithmic curation blurs the boundary between human and machine agency.

When our cultural choices are shaped by opaque and largely automated systems, it becomes harder to distinguish between our own preferences and those that have been subtly influenced or even manufactured by algorithms.

The Loss of Authenticity.

Postmodernism is often associated with a "crisis of authenticity", a sense that in a world of mass reproduction and simulation, the very notion of originality and realness becomes suspect. This crisis is exacerbated by the rise of algorithmic curation, which further distances us from the sources of cultural production and meaning-making.

In his awesome book "Simulacra & Simulation," my old mucker Monsieur Jean de Baudrillard argues that in the postmodern age, reality itself is replaced by simulations and representations. He describes a world of "hyperreality," where the distinction between the real and the artificial breaks down, and where copies and models precede and determine the real.

I wrote another post about hyperreality and the war in Ukraine, if you're interested.

I'm pretty sure these algorithmic recommendation systems can be seen as engines of hyperreality, generating personalised simulations of the world that feel more real and engaging than the messy, unfiltered offline world.

When our news feeds, streaming queues, and search results are tailored to our individual profiles, we may start to mistake this curated version of reality for reality itself.

Indeed, the logic of algorithmic curation prioritises content that is easily reproducible and shareable over more unique or challenging forms of expression. Viral memes, catchy soundbites, and formulaic genres tend to thrive in this environment, while more niche or experimental work may struggle to find an audience. This is leading to a flattening of cultural diversity and a loss of authentic, localised forms of creativity.

I know what you're thinking: the notion of authenticity itself is problematic from a postmodern perspective, isn't it? If all culture is a construct, a play of signs and simulations, then the very idea of an authentic or original expression becomes suspect. Nonetheless, the dominance of algorithmic curation raises valid concerns about the homogenisation of culture and the erosion of human agency in the creation and interpretation of meaning.

If that makes sense.

Social Distinction and Algorithmic Taste.

My old pal Pierre Bourdieu famously argued that cultural taste is not simply a matter of individual preference, but a powerful marker of social distinction.

In his book "Distinction: A Social Critique of the Judgement of Taste," Bourdieu shows how cultural consumption - from the music we listen to, to the food we eat, to the way we dress - serves to reinforce class boundaries and power hierarchies.

(I wrote about this idea in terms of why we all find certain things aesthetically pleasing. You can read it here.)

For Bourdy, taste is not innate or purely individual, but is shaped by one's social position and the cultural capital one inherits and acquires. Those with high levels of cultural capital - typically the educated, upper-middle classes - have the ability to appreciate and engage with highbrow culture, which serves as a form of social currency and distinction.

In the age of algorithmic curation, however, the traditional markers of cultural capital are being disrupted and reconfigured. On one level, algorithmic systems can be seen as a democratising force, making a wider range of cultural content accessible to more people, regardless of their social background or formal education.

However, this apparent democratisation can also serve to reinforce existing power structures in new ways.

The data used to train recommendation algorithms often reflects and amplifies historical inequalities and biases. If marginalized communities have had less access to certain forms of culture or technology, this lack of engagement may be interpreted by algorithms as a lack of interest, leading to a self-reinforcing cycle of exclusion.

The ability to navigate and manipulate algorithmic systems is becoming a new form of cultural capital in its own right.

Those who understand how these systems work, who know how to optimise their profiles and gaming the algorithms, can gain significant social and economic advantages. This algorithmic savvy is definitely not evenly distributed, but tends to concentrate among the already privileged.

At the same time, the flattening of taste brought about by algorithmic recommendations is changing the very nature of social distinction. In a world where everyone has access to the same personalised content feeds, traditional forms of cultural snobbery and one-upmanship become less relevant. Instead, we may see the emergence of new forms of distinction based on one's ability to curate a unique and authentic-seeming digital persona, or to cultivate niche and underground tastes that resist algorithmic classification.

The Struggle for Agency and Serendipity.

So, where are we now? Well, the rise of algorithmic curation poses challenges to traditional notions of cultural agency and meaning-making. When our tastes and preferences are increasingly shaped by automated systems, it can feel like we are losing control over our own cultural identities and experiences.

The efficiency and personalisation of algorithmic recommendations is coming at the cost of serendipity and surprise. Some of the most meaningful cultural experiences are those that catch us off guard, that expose us to something new and unexpected. The serendipitous discovery of a life-changing book in a used bookstore, the chance encounter with a stranger that sparks a deep conversation, the stumbling upon a street performance that shifts our perspective - these kinds of experiences are becoming rarer in a world mediated by algorithms.

That's why it's always good to truly explore a place, in order to be thrilled by the unexpected.

Of course, serendipity is not entirely lost in the age of algorithmic curation. Recommendation systems can sometimes surface content that we would never have found on our own, for sure, and social media can facilitate chance connections across geographic and cultural boundaries. Nevertheless, these moments of algorithmic serendipity are often constrained by the parameters of our existing preferences and social networks.

Moreover, this illusion of serendipity can be actively manufactured by algorithms in ways that are not transparent to users. The "discover weekly" playlists on Apple Music, for example, are presented as personalised collections of new and unexpected music, but are in fact generated by complex algorithms that take into account factors like popularity, novelty, and perceived similarity to the user's existing tastes.

In this context, the struggle for cultural agency and serendipity becomes a matter of actively resisting the totalising logic of algorithmic curation. This might involve seeking out offline or analog cultural experiences, cultivating a sense of critical distance from one's digital feeds, or actively working to diversify one's information diet and social connections.

It also involves pushing for greater transparency and accountability from the platforms and systems that shape our cultural lives. As users and citizens, we have a right to know how these systems work, what data they are collecting, and how they are shaping our perceptions and behaviours. We probably need to demand more control over our own data and more agency in determining the algorithms that curate our world.

Just Stop Algorithms?

I don't think the rise of algorithmic curation is a neutral or inevitable development, but instead a complex and contested process with deep implications for our cultural, social, and political lives.

To my mind, the logic of algorithmic recommendations embodies and accelerates many of the key features of postmodernism, from the fragmentation of grand narratives to the blurring of cultural boundaries to the crisis of authenticity.

At the same time, these systems interact with and reshape existing structures of power and distinction in ways that are not always visible or predictable. The apparent democratisation of culture brought about by algorithmic curation can actually serve to reinforce social hierarchies and inequalities, while the flattening of taste creates new forms of distinction and exclusion.

As individuals (and as a society), we need to grapple with these challenges and develop new forms of cultural agency and resistance. This means cultivating a critical awareness of how algorithmic systems shape our perceptions and behaviours, actively seeking out diverse and challenging cultural experiences, and pushing for greater transparency and accountability from the platforms and institutions that mediate our digital lives.

Ultimately, though, the struggle for meaning and authenticity in the age of algorithmic curation is not a lost cause, but an ongoing process of negotiation and contestation.

By engaging critically and creatively with the systems that shape our world, we can work to preserve a sense of human agency and serendipity in the face of technological determinism.

We can strive to create a digital culture that is not just personalised and efficient, but also diverse, inclusive, and open to the unexpected.

If you're up for it, I am...

<SwmMeta version="3.0.0" repo-id="Z2l0aHViJTNBJTNBZG9jcyUzQSUzQWVsZW1lbnRhbHNvYnJpZXR5" repo-name="docs"><sup>Powered by [Swimm](https://app.swimm.io/)</sup></SwmMeta>
